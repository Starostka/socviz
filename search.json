[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Social Data and Visualization",
    "section": "",
    "text": "Melbourne Pulse\n\n\n\nImage of Melbourne by Dmitry Osipenko from Unsplash\n\n\nWelcome to Melbourne Pulse - Let’s unveile Melbourne’s Dynamic Story! We are glad to introduce Melbourne urban deveploment by drawing the picture of the city through the lens of data. This is not only a story about charts and numbers, but also the story that help you get to know this vibrant and dynamic metropolis.\nA more elaborate notebook to meet the final project requirements can be downloaded using the following link.\nDownload Notebook\nWe hope you enjoy the journey with us!\n\n\n\n\nReuseCC"
  },
  {
    "objectID": "pages/melbourne_details.html",
    "href": "pages/melbourne_details.html",
    "title": "Data details",
    "section": "",
    "text": "Details about the Melbourne forecast data\n\nThe data used is available at City of Melbourne open data portal\n\nHere’s a brief summary for each of the datasets used for this project.\n\nCity of Melbourne Jobs Forecasts by Small Area 2021-2041\n\n585 KB, 9114 rows, 5 cols, geodata: area name, age and gender\n\nCity of Melbourne Population Forecasts by Small Area 2021-2041\n\n710 KB, 17052 rows, 5 cols, geodata: area name\n\nCity of Melbourne Dwellings and Household Forecasts by Small Area 2021-2041\n\n161 KB, 2646 rows, 5 cols, geodata: area name\n\nCity of Melbourne Floor Space Forecasts by Small Area 2021-2041\n\n834 KB, 9996 rows, 5 cols, geodata: area name\n\nDevelopment Activity Monitor\n\n328 KB, 1430 rows, 42 cols, geodata: yes\n\n\n\n\n\n\nReuseCC"
  },
  {
    "objectID": "pages/melbourne.html",
    "href": "pages/melbourne.html",
    "title": "Introduction",
    "section": "",
    "text": "Show the code\nimport polars as pl\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotx\n\nplt.style.use(matplotx.styles.dufte)\n\n\n\n1 About Melbourne\nMelbourne holds the distinction of being the second most populous city in both Australia and Oceania. As the center of south Australia, Melbourne is a sprawling urban area spanning 9,992 km2, which encompasses a metropolitan region comprising 31 municipalities (Source: Wikipedia). It has a population of 5 million, which takes up 19% of the population of Australia.\nThe initiative of this narrative data story is to provide you with an opportunity to delve into Melbourne’s city life through various data sets, including demographics, residential information, and employment data. By examining these aspects, you can see the potential opportunities in the city. Furthermore, we want to show the pictures of the future for Melbourne by applying the city’s forecasts data, and provide you with the insights of the city’s future development.\n\nThe data used is available at City of Melbourne open data portal\n\nHere’s a brief summary for each of the datasets used for this project.\n\nCity of Melbourne Jobs Forecasts by Small Area 2021-2041\n\n585 KB, 9114 rows, 5 cols, geodata: area name, age and gender\n\nCity of Melbourne Population Forecasts by Small Area 2021-2041\n\n710 KB, 17052 rows, 5 cols, geodata: area name\n\nCity of Melbourne Dwellings and Household Forecasts by Small Area 2021-2041\n\n161 KB, 2646 rows, 5 cols, geodata: area name\n\nCity of Melbourne Floor Space Forecasts by Small Area 2021-2041\n\n834 KB, 9996 rows, 5 cols, geodata: area name\n\nDevelopment Activity Monitor\n\n328 KB, 1430 rows, 42 cols, geodata: yes\n\n\n\n\n\n\nReuseCC"
  },
  {
    "objectID": "pages/melbourne_population.html",
    "href": "pages/melbourne_population.html",
    "title": "Population and Demographics",
    "section": "",
    "text": "Show the code\nimport pandas as pd\nimport cufflinks as cf\nimport plotly\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.subplots as sp\n%matplotlib inline\nimport math\nfrom matplotlib import pyplot as plt\nfrom sklearn import model_selection, tree, metrics, ensemble\nfrom sklearn.preprocessing import MinMaxScaler\nfrom bokeh import models, plotting\nfrom bokeh.palettes import Spectral8, Spectral11\nimport seaborn as sns\nimport pycountry as pc\nfrom bokeh.models import HoverTool\nfrom bokeh.plotting import figure, show\nfrom bokeh.models import  ColumnDataSource, Legend, LinearAxis, FactorRange\nfrom bokeh.io import output_notebook, show, curdoc\nfrom bokeh.palettes import Spectral6, Category20b\nfrom bokeh.transform import factor_cmap\nfrom bokeh.models import BoxAnnotation\nfrom bokeh.models import Title\nfrom bokeh.layouts import layout\nfrom bokeh.models import Tabs, TabPanel, Range1d\n\nfrom pandas_geojson import to_geojson\n\noutput_notebook()\nimport bokeh.models as bkm\nfrom bokeh.resources import INLINE\nimport bokeh.io\nfrom bokeh import *\nbokeh.io.output_notebook(INLINE)\nimport regex as re\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \ninit_notebook_mode(connected=True)\ncf.go_offline()\n\n\n\n    \n        \n        Loading BokehJS ...\n    \n\n\n\n\n\n\n\n    \n        \n        Loading BokehJS ...\n    \n\n\n\n\n\n\n\n1 Global Population\nPopulation growth is impacting our planet in many ways. According to Population Media Center, when looking back over the last several centuries, global population trends show continuous expansion, both in terms of volume and rapidity. Population is the key factor in the climate crisis, housing and infrastructure, economic growth of a country, and so on. Therefore, a proper forecast of population growth can guide the society to make better decisions in the future.\nLooking into the data globally, we can get the insight from the expanding of population across the world and it’s correlations. To start with, we will bring the data from the World Bank and analyze the correlation from population to the other demographics features.\n\n\nShow the code\nworld_data = pd.read_csv('../data/countries-of-the-world.csv', decimal=',')\n\nfor col in world_data.columns.values:\n    if world_data[col].isnull().sum() == 0:\n        continue\n    if col == 'Climate':\n        guess_values = world_data.groupby('Region')['Climate'].apply(lambda x: x.mode().max())\n    else:\n        guess_values = world_data.groupby('Region')[col].median()\n    for region in world_data['Region'].unique():\n        world_data[col].loc[(world_data[col].isnull())&(world_data['Region']==region)] = guess_values[region]\n\nplt.figure(figsize=(10,10))\nsns.heatmap(data=world_data.iloc[:,2:].corr(),annot=True,fmt='.2f',cmap='coolwarm', \n            annot_kws={\n                'fontsize': 7,\n                'fontweight': 'bold'\n            })\nplt.title('Demographics correlation between different features')\nplt.show()\n\n\n\n\n\n\n\n2 Aging issue in Melbourne\nIn a global scale, the birthrate and deadrate have negative correlation to the population. Inspired by the fact, we want to look into the aging issue in Melbourne.\n\n\nShow the code\ndf_population = pd.read_csv('../data/city-of-melbourne-population-forecasts-by-small-area-2020-2040.csv')\n\ndf_age = df_population.drop(df_population[df_population['Age'].isin(['Total population', 'Average age'])].index)\ndf_age = df_age.drop(df_age[df_age['Geography'].isin(['City of Melbourne'])].index)\n\nfig = px.bar(df_age, x='Year', y='Value', color='Age', barmode='group', title='Total population by Age from 2021 to 2041')\nfig.show()\n\n\n\n                                                \n\n\nThe age group from 25-40 is dominating the growth of total population in Melbourne, which shows that Melbourne is a young city. However, the aging issue is still a concern. Defined the elderly age group as 65+, from the data we can see that the population of elderly age group is increasing by the a fast pace.\n\n\nShow the code\ndf_elderly = df_population[df_population['Age'].isin(['Age 65-69', 'Age 70-74', 'Age 75-79', 'Age 80-84', 'Age 85+'])]\n\ndf_elderly = df_elderly.groupby(['Year', 'Age']).sum().reset_index()\nfig = px.line(df_elderly, x='Year', y='Value', color='Age', title='Population of Elderly from 2021 to 2041')\nfig.show()\n\n\n/var/folders/b4/g666m_w53g9121tp3r4qmzth0000gn/T/ipykernel_30834/2492635057.py:3: FutureWarning:\n\nThe default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n\n\n\n\n                                                \n\n\nAs a young and developed city, Melbourne is also facing the aging issue. This is a challenge for the city to provide the service and proper resources such as healthcare, dwellings and social care for the elderly.\n\n\n3 Popular areas for elderly\n\n\nShow the code\ngeoinfo = pd.read_csv('../data/small_area_geo_info.csv')\ngeoinfo.rename(columns={'featurenam': 'Geography'}, inplace=True)\n\ndf_pop_area = pd.merge(df_age, geoinfo, on='Geography')\ndf_pop_area = df_pop_area[df_pop_area['Age'].isin(['Age 65-69', 'Age 70-74', 'Age 75-79', 'Age 80-84', 'Age 85+'])]\ndf_pop_area.drop(['shape_area', 'shape_len'], axis=1, inplace=True)\n\ndf_pop_area = df_pop_area[df_pop_area['Year'].isin([2041])]\ndf_pop_area['AreaTotal'] = df_pop_area.groupby('Geography')['Value'].transform('sum')\n\ndf_pop_area['Lat'] = df_pop_area['Geo Point'].apply(lambda x: x.split(', ')[0])\ndf_pop_area['Lon'] = df_pop_area['Geo Point'].apply(lambda x: x.split(', ')[1])\ndf_pop_area['Lat'] = pd.to_numeric(df_pop_area['Lat'])\ndf_pop_area['Lon'] = pd.to_numeric(df_pop_area['Lon'])\n\nfig = px.scatter_mapbox(df_pop_area, \n                        lat='Lat', \n                        lon='Lon', \n                        hover_name='Geography', \n                        hover_data=['AreaTotal'],\n                        color='AreaTotal', \n                        opacity=0.8,\n                        color_continuous_scale='Jet', \n                        size='AreaTotal',\n                        zoom=11, title='Elderly Population Distribution by Small Area by 2041')\n\nfig.update_layout(mapbox_style='open-street-map')\nfig.update_layout(margin={'r': 0, 't': 40, 'l': 0, 'b': 0})\n\nfig.show()\n\n\n\n                                                \n\n\nBy 2041, the most popular area for the elderly remains as Melbourne CBD with its advantages of convenient city infrastructure and facilities. However, despite the city center, North Melbourne, Southbank and Docklands are also popular for the elderly people, with the quiet and peaceful environment.\n\n\n4 Takeaways\nBased on the analysis, we can conclude that the population growth in the next 20 years: - The population of Melbourne is predominantly composed of young individuals, primarily between the ages of 25 and 40, driving the overall population growth. - Melbourne continues to face concerns regarding its aging population, as the number of elderly individuals is increasing at a rapid rate.\n\n\n\n\nReuseCC"
  },
  {
    "objectID": "pages/melbourne_residential.html",
    "href": "pages/melbourne_residential.html",
    "title": "Household and Floor Space",
    "section": "",
    "text": "Show the code\nimport pandas as pd\nimport cufflinks as cf\nimport plotly\nimport plotly.express as px\nimport plotly.graph_objects as go\n%matplotlib inline\nimport math\nfrom matplotlib import pyplot as plt\nfrom sklearn import model_selection, tree, metrics, ensemble\nfrom sklearn.preprocessing import MinMaxScaler\nfrom bokeh import models, plotting\nfrom bokeh.palettes import Spectral8, Spectral11\nimport seaborn as sns\nimport pycountry as pc\nfrom bokeh.models import HoverTool\nfrom bokeh.plotting import figure, show\nfrom bokeh.models import  ColumnDataSource, Legend, LinearAxis, FactorRange\nfrom bokeh.io import output_notebook, show, curdoc\nfrom bokeh.palettes import Spectral6, Category20b\nfrom bokeh.transform import factor_cmap\nfrom bokeh.models import BoxAnnotation\nfrom bokeh.models import Title\nfrom bokeh.layouts import layout\nfrom bokeh.models import Tabs, TabPanel, Range1d\n\noutput_notebook()\nimport bokeh.models as bkm\nfrom bokeh.resources import INLINE\nimport bokeh.io\nfrom bokeh import *\nbokeh.io.output_notebook(INLINE)\nimport regex as re\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \ninit_notebook_mode(connected=True)\ncf.go_offline()\n\n\n\n    \n        \n        Loading BokehJS ...\n    \n\n\n\n\n\n\n\n    \n        \n        Loading BokehJS ...\n    \n\n\n\n\n\n\n\n1 Growth Overview\nWith the sharp increase in the number of population, households are also expected to grow in a similar pattern in order to accommodate the population. Based on the rapid growth of population, we are able to observe that in next 20 years, the number of households and floor space will increase accordingly.\n\n\nShow the code\ndf_population = pd.read_csv('../data/city-of-melbourne-population-forecasts-by-small-area-2020-2040.csv')\ndf_household = pd.read_csv('../data/city-of-melbourne-dwellings-and-household-forecasts-by-small-area-2020-2040.csv')\ndf_floorspace = pd.read_csv('../data/city-of-melbourne-floor-space-forecasts-by-small-area-2020-2040.csv')\n\ndf_age = df_population.drop(df_population[df_population['Age'].isin(['Total population', 'Average age'])].index)\ndf_age = df_age.drop(df_age[df_age['Geography'].isin(['City of Melbourne'])].index)\n\ndf_household = df_household.drop(df_household[df_household['Geography'].isin(['City of Melbourne'])].index)\ndf_household = df_household.drop(df_household[df_household['Households'].isin(['Not applicable', 'Total households'])].index)\n\ndf_floorspace = df_floorspace.drop(df_floorspace[df_floorspace['Geography'].isin(['City of Melbourne'])].index)\ndf_floorspace = df_floorspace.drop(df_floorspace[df_floorspace['Industry Space Use'].isin(['Total residential floorspace'])].index)\ndf_floorspace = df_floorspace.drop(df_floorspace[df_floorspace['Industry Space Use'].isin(['Total employment floorspace'])].index)\n\nhouseholds_by_year = df_household.groupby(['Year']).sum()\nhouseholds_by_year = households_by_year['Value'].to_frame().reset_index()\nfloor_by_year = df_floorspace.groupby(['Year']).sum()\nfloor_by_year = floor_by_year['Value'].to_frame().reset_index()\ndf_age = df_age.groupby(['Year']).sum()\ndf_age = df_age['Value'].to_frame().reset_index()\n\nforecast_overview = pd.merge(households_by_year, floor_by_year, on='Year')\nforecast_overview = pd.merge(forecast_overview, df_age, on='Year')\n\nforecast_overview.rename(columns={'Value_x': 'Households', 'Value_y': 'Floor Space', 'Value': 'Population'}, inplace=True)\n\ncolumns_to_normalize = ['Households', 'Floor Space', 'Population']\n\n# Initialize the scaler\nscaler = MinMaxScaler()\nnormalized_data = scaler.fit_transform(forecast_overview[columns_to_normalize])\n\ndf_normalized = pd.DataFrame(normalized_data, columns=columns_to_normalize)\ndf_normalized = pd.concat([forecast_overview['Year'], df_normalized], axis=1)\n\n# Viz the normalized data\ndf_long = pd.melt(df_normalized, id_vars='Year', var_name='Category', value_name='Value')\n\n# Create the bar plot using Plotly Express\nfig = px.bar(df_long, x='Year', y='Value', color='Category',\n             title='Population, Dwelling and Floor Space Forecast Overview (Normalized)',\n             labels={'Year': 'Year', 'Value': 'Value'}, barmode='group')\n\nfig.update_layout(width=600, height=500, title_font_size=13)\n\n# Show the plot\nfig.show()\n\n\n\n                                                \n\n\nThe growth of households and floor space reflects the fact that Melbourne is a pleasant city for people to live in. The municipality of Melbourne has dedicated efforts to enhance the residents’ quality of life. By investing in infrastructure and public amenities, the city aims to create a more livable environment. How about different small areas in Melbourne? Are they all growing at the same pace?\n\n\nShow the code\nforecast_overview_viz = pd.merge(forecast_overview, df_normalized, on='Year')\nforecast_overview_viz.rename(columns={'Households_x': 'Households', 'Floor Space_x': 'Floor_Space', 'Population_x': 'Population', 'Households_y': 'Households (Normalized)', 'Floor Space_y': 'Floor_Space (Normalized)', 'Population_y': 'Population (Normalized)'}, inplace=True)\n\nsource = models.ColumnDataSource(forecast_overview_viz)\n\np1 = plotting.figure(title='Melbourne Forecast Overview (Normalized)', x_axis_label='Year', y_axis_label='Population', width=700, height=350)\n\nplot1 =p1.line(x='Year', y='Population (Normalized)', source=source, legend_label='Population', line_width=3, color=Spectral11[1])\nplot2 =p1.line(x='Year', y='Households (Normalized)', source=source, legend_label='Households', line_width=3, color=Spectral11[3])\nplot3 =p1.line(x='Year', y='Floor_Space (Normalized)', source=source, legend_label='Floor_Space', line_width=3, color=Spectral11[5])\n\np1.add_tools(models.HoverTool(renderers=[plot1], tooltips=[('Year', '@Year'), ('Population', '@Population')]))\np1.add_tools(models.HoverTool(renderers=[plot2], tooltips=[('Year', '@Year'), ('Households', '@Households')]))\np1.add_tools(models.HoverTool(renderers=[plot3], tooltips=[('Year', '@Year'), ('Floor Space', '@Floor_Space sqm')]))\n\np1.legend.location = 'top_left'\np1.legend.background_fill_alpha = 0.25\np1.legend.background_fill_color = 'darkgray'\np1.legend.border_line_alpha = 0\np1.title.align = 'center'\n\n\ndf_household.rename(columns={'Value': 'Number of Households'}, inplace=True)\ndf_household_area = df_household.groupby(['Year', 'Geography']).sum()\n# df_household_area.drop(columns=['Households', 'Category'], inplace=True)\ndf_household_area.reset_index(inplace=True)\ndf_household_area\n\ndf_household_area = df_household_area.pivot(index='Year', columns='Geography', values='Number of Households')\n\nsource = models.ColumnDataSource(df_household_area)\n\nareas = df_household['Geography'].unique().tolist()\nyears = df_household['Year'].unique().tolist()\nyears = years.sort()\n\np2 = figure(title='Melbourne Households Forecast by Small Area', x_axis_label='Year', y_axis_label='Number of Households', width=700, height=350)\n\nbar = {}\nfor indx, i in enumerate(areas):\n    bar[i] = p2.vbar(x=\"Year\", top=i, width=0.3, \n                    source=source, muted_alpha=0.2, muted=False, color=Category20b[14][indx])\n\nlegend = Legend(items=[(x, [bar[x]]) for x in areas], location=(0, -30))\np2.add_layout(legend, 'right')\n\np2.legend.background_fill_alpha = 0.25\np2.legend.border_line_alpha = 0\np2.title.align = 'center'\np2.legend.click_policy = 'hide'\n\ndf_floorspace.rename(columns={'Value': 'Area of Floor Space'}, inplace=True)\ndf_floorspace_area = df_floorspace.groupby(['Year', 'Geography']).sum()\n# df_floorspace_area.drop(columns=['Industry Space Use', 'Category'], inplace=True)\ndf_floorspace_area.reset_index(inplace=True)\ndf_floorspace_area = df_floorspace_area.pivot(index='Year', columns='Geography', values='Area of Floor Space')\n\nsource = models.ColumnDataSource(df_floorspace_area)\n\nareas = df_floorspace['Geography'].unique().tolist()\nyears = df_floorspace['Year'].unique().tolist()\nyears = years.sort()\n\np3 = figure(title='Melbourne Floor Space Forecast by Small Area', x_axis_label='Year', y_axis_label='Area of Floor Space', width=700, height=350)\n\nbar = {}\nfor indx, i in enumerate(areas):\n    bar[i] = p3.vbar(x=\"Year\", top=i, width=0.3, \n                    source=source, muted_alpha=0.2, muted=False, color=Category20b[14][indx])\n\nlegend = Legend(items=[(x, [bar[x]]) for x in areas], location=(0, -30))\np3.add_layout(legend, 'right')\n\np3.legend.background_fill_alpha = 0.25\np3.legend.border_line_alpha = 0\np3.title.align = 'center'\np3.legend.click_policy = 'hide'\n\n\ntab1 = TabPanel(child=p1,title=\"Forecast Overview\")\ntab2 = TabPanel(child=p2,title=\"Households by Small Area\")\ntab3 = TabPanel(child=p3,title=\"Floor Space by Small Area\")\n\ntabs = Tabs(tabs=[tab1, tab2, tab3])\n\ncurdoc().add_root(tabs)\n\nshow(tabs)\n\n\n\n  \n\n\n\n\n\nBy 2041, the City of Melbourne is forecast to reach 136,000 households, accommodating an additional 50,000 households between 2021 and 2041. Floor space demand is expected to grow by over 6.3 million square metres between 2021 and 2041, of which 2.7 million square metres is residential.\nMelbourne (CBD) dominates the floor space within the Melbourne municipality, showcasing the most significant projected growth over the next 20 years. North Melbourne, Southbank, Docklands and Carlton are the other suburbs that are expected to have a significant increase by the amount of floor space. The rest of areas remains relatively stable.\nDespite of Melbourne CBD, Carlton, North Melbourne and Southbank are predicted to have a notable increase in the number of households. The prediction may be due to the rapid development and resource allocation in these areas, rendering them more appealing as residential destinations. The reason of Mebelbourne dominating the floor space is that it is the central business district of Melbourne, which is the main commercial and administrative centre of the city, with the most convenient transportation and the most prosperous business.\n\n\n2 Takeaways\nBy looking at the households and floor space forecast data in Merbourne, we are able to conclue that: - Over the next twenty years, Melbourne CBD is expected to retain its status as the city center with the highest population density and the largest number of households. - The expansion of households and floor space is failing to keep pace with the growth of the population, therefore more space in the suburb will be developed to accommadate more and more people in Melbourne.\n\n\n\n\nReuseCC"
  },
  {
    "objectID": "pages/melbourne_job.html#employment-impact-for-the-younger-workforce",
    "href": "pages/melbourne_job.html#employment-impact-for-the-younger-workforce",
    "title": "Employment and Jobs",
    "section": "2.1 Employment impact for the younger workforce",
    "text": "2.1 Employment impact for the younger workforce\nWith the expected increase in population, especially for young adults. One might think that’s partly a result of an increase in job opportunities. Here we consider the younger group of women and the industry space of finance and insurance.\n\n\nShow the code\njobs = pl.read_csv('../data/jobs_forecast.csv', ignore_errors=True, try_parse_dates=True)\njobs_industry = jobs.filter(pl.col('Category') == 'Jobs by industry').sort('Year')\njobs_industry = jobs_industry.filter(pl.col('Geography') == 'City of Melbourne')\njobs_industry = jobs_industry.filter(pl.col('Industry Space Use') == 'Finance and insurance')\n#jobs_industry['Year'].max()\n\npopulation = pl.read_csv('../data/population_forecast.csv', ignore_errors=True, try_parse_dates=True)\npopulation = population.filter(pl.col('Geography') == 'City of Melbourne')\npopulation = population.filter(pl.col('Gender') == 'Female')\n# population = population.filter(pl.col('Age') == 'Average age')\npopulation = population.filter(pl.col('Age') == 'Age 20-24')\n\njoined = jobs_industry.join(population, on='Year', suffix='_population')\njoined = joined.rename({\"Value\": \"Jobs\", \"Value_population\": \"Population\"})\n\ncorr = joined[['Year', 'Jobs', 'Population']]\n\nf, ax = plt.subplots(figsize=(8, 5))\n\nsns.heatmap(corr[['Year', 'Jobs', 'Population']].corr(), annot=True) \n\nplt.title('Correlation matrix', size=12)\nax.set_xticklabels(list(corr[['Year', 'Jobs', 'Population']].columns), size=12, rotation=90)\nax.set_yticklabels(list(corr[['Year', 'Jobs', 'Population']].columns), size=12, rotation=0)\nplt.show()\n\n\n\n\n\nThe last couple of years have seen an increase in automation and so called “smart banks”, also known as “fintech” institutions. They are keen on adopting the newest in technology and often houses employees with higher levels of education needed to sustain the digital demands. The positive correlation here is vague to assume alone on the population and jobs. But we still think it is fair to say that young adults recently graduated is attracted by these cooporate firms."
  },
  {
    "objectID": "pages/conclusion.html",
    "href": "pages/conclusion.html",
    "title": "Summary",
    "section": "",
    "text": "ReuseCC"
  },
  {
    "objectID": "pages/san_francisco.html",
    "href": "pages/san_francisco.html",
    "title": "Analysis and Visualization",
    "section": "",
    "text": "Show the code\nimport folium\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom bokeh.models import ColumnDataSource, FactorRange\nfrom bokeh.io import output_notebook\nfrom bokeh.models import ColumnDataSource\nfrom bokeh.plotting import figure, show\nfrom bokeh.sampledata.commits import data\nfrom bokeh.transform import jitter\nfrom bokeh.palettes import HighContrast3\nfrom bokeh.plotting import figure, show\nfrom bokeh.io import show\nfrom bokeh.layouts import row, column\nfrom bokeh.models import CustomJS, RadioButtonGroup\nfrom bokeh.models import TabPanel, Tabs\nfrom bokeh.plotting import figure, show\nfrom bokeh.models import Paragraph\nfrom bokeh.transform import dodge\nfrom folium.plugins import HeatMap\nfrom bokeh.palettes import Category20\n\nimport matplotx\n\nplt.style.use(matplotx.styles.dufte)"
  },
  {
    "objectID": "pages/san_francisco.html#dataset",
    "href": "pages/san_francisco.html#dataset",
    "title": "Analysis and Visualization",
    "section": "1.1 Dataset",
    "text": "1.1 Dataset\nIn this story, we will examine the San Francisco Police Department’s (SFPD) Incient Report Dataset, which covers the period from January 2003 to May 2018.\nThe dataset contains information on criminal incidents reported in San Francisco, including the incident date, time, category, police district, latitude, longitude, and more. It comprises over 2 million records of crimes, with 35 columns of data.\nThe dataset reveals that 37 categories of crimes were recorded across the city of San Francisco."
  },
  {
    "objectID": "pages/san_francisco.html#abstract",
    "href": "pages/san_francisco.html#abstract",
    "title": "Analysis and Visualization",
    "section": "1.2 Abstract",
    "text": "1.2 Abstract\nThe aim of this report is utilizing the techniques of data visualization for the analytics of crime occured in San Francisco. The primary idea of this data analysis study is to obtain the insights from the observation, in order to evaluate the criminal situation for the past decades in San Francisco, as well as help prevent potential crimes in the future.\nThe data analysis will be based on Time-Series, Geographic and Interative Visualization respectively.\nAccording to SFNext Index, with the exception of robberies, violent crime in San Francisco is below average for large cities. In 2019 and 2020, San Francisco ranked in the bottom half among major U.S. cities, with rates of 670 and 540 violent crime incidents per 100,000 residents, respectively. Hence, we are interested in how Robbery had increased the violent crime level in San Francisco."
  },
  {
    "objectID": "pages/san_francisco.html#timeseries-how-the-occurrence-of-robbery-changed-over-the-time",
    "href": "pages/san_francisco.html#timeseries-how-the-occurrence-of-robbery-changed-over-the-time",
    "title": "Analysis and Visualization",
    "section": "2.1 Timeseries: How the occurrence of Robbery changed over the time?",
    "text": "2.1 Timeseries: How the occurrence of Robbery changed over the time?\n\nIf we divide the time of the incidents into hourly timeslots, it becomes apparent that the number of robberies reaches its highest point between 2 and 3 pm and remains consistently high until 5 pm. After 5 pm, there is a sharp decline during the evening, but a secondary peak occurs between 1 and 2 am.Between 2 am and 2 pm, the number of incidents increases steadily.\n\n\nShow the code\ndf_before_2018 = pl.read_csv('../data/before_2018.csv').to_pandas()\n\nfocuscrimes = ['ROBBERY']\n\nhour_of_day = [i for i in range(0,24)]\nhourly_slots = {}\nfor i in range(len(hour_of_day)):\n    if i+1 == len(hour_of_day):\n        start = hour_of_day[i]\n        end = hour_of_day[0]\n        hourly_slots[start] = str(start) + \"-\" + str(end)\n    else:\n        start = hour_of_day[i]\n        end = hour_of_day[i+1]\n        hourly_slots[start] = str(start) + \"-\" + str(end)\n\ndf_before_2018[\"time_period\"] = [hourly_slots[int(str(i).split(\":\")[0])] for i in list(df_before_2018['Hour'])]\n\nyearly_pattern = df_before_2018.groupby(by=[\"Year\", \"Category\"]).size().reset_index(name=\"Count\")\n\nyearly_pattern = yearly_pattern.loc[yearly_pattern['Category'].isin(focuscrimes)].reset_index(drop=True)\n\nhourly_pattern = df_before_2018.groupby(by=[\"time_period\", \"Category\"]).size().reset_index(name=\"Count\")\n\nhourly_pattern = hourly_pattern.loc[hourly_pattern['Category'].isin(focuscrimes)].reset_index(drop=True)\n\n\nplt.figure(figsize=(7.5,5))\nplt.suptitle(\"Robbery Incidents in Time-series\" ,fontsize=14, y=1.0, fontweight='bold', color='black')\n\n# Yealy trend\ntemp1 = yearly_pattern.loc[yearly_pattern['Category'] == 'ROBBERY'].reset_index(drop=True)\nx = temp1[\"Year\"]\ny = temp1[\"Count\"]\nplt.subplot(2,2,1)\nplt.title('Robbery Incidents Yealy Pattern', pad=-14, fontsize = 9, fontweight='bold', fontstyle=\"italic\")\nplt.bar(x, y, width=0.6, edgecolor=\"black\", color='lavender')\nplt.xticks(x, yearly_pattern['Year'].unique().tolist(), rotation=45, fontsize = 7)\nplt.tight_layout()\nplt.ylim(top=(np.max(y)+(np.max(y)*0.3)))\n\n# Hourly trend\ntemp2 = hourly_pattern.loc[hourly_pattern['Category'] == 'ROBBERY'].reset_index(drop=True)\nx = temp2[\"time_period\"]\ny = temp2[\"Count\"]\nplt.subplot(2,2,2)\nplt.title('Robbery Incidents Hourly Pattern', pad=-14, fontsize = 9, fontweight='bold', fontstyle=\"italic\")\nplt.bar(x, y, width=0.6, edgecolor=\"black\", color='lavender')\nplt.xticks(x, hourly_slots.values(), rotation=45, fontsize = 6)\nplt.tight_layout()\nplt.ylim(top=(np.max(y)+(np.max(y)*0.3)))\n\n# Calplot\nimg = mpimg.imread('../assets/Calplot_2012.png')\nplt.subplot(2,1,2)\nplt.imshow(img)\nplt.axis('off')\n\nplt.tight_layout()\n\n\n\n\n\nFrom 2003 to 2017, we can see the incidents fluctuated accross years. Specifically, in 2010 and 2011, it has a significant decreased from 2008 and 2009. The Rand Corporation studied this phenomenon on a national level in 2010, concluding that the crime prevention benefit of hiring more officers is well worth the cost. Reference\nHowever, there was a resurgence in incidents in 2012, with a noticeable gap from the previous year. After analyzing the robbery incidents data in 2012, we observed a marked increase in robberies on the final Sunday in June in San Francisco.\nFurther investigation revealed that this date coincided with the San Francisco LGBT Pride Parade, which started at Beale Street and Market Street and continued down to 8th Street."
  },
  {
    "objectID": "pages/san_francisco.html#map-where-does-robbery-most-likely-take-place",
    "href": "pages/san_francisco.html#map-where-does-robbery-most-likely-take-place",
    "title": "Analysis and Visualization",
    "section": "2.2 Map: Where does robbery most likely take place?",
    "text": "2.2 Map: Where does robbery most likely take place?\n\nLet’s examine the robbery locations on June 24, 2012, during the Pride Parade in San Francisco which typically occurs on Market Street(Reference: Wikipedia).\nIn the visualization of the robbery incidents data on the day when the Pride Parade occured, the three location marks Market Street, 8th Street and Beala Street respectively. The red dots indicates the location of the robberies taking place. It shows an obvious fact that in the 33 incidents recorded on 24 June 2012, most of the crimes happened in the range of the routes that the parade covered.\n\n\n\nShow the code\ndf_before_2018 = pl.read_csv('../data/before_2018.csv').to_pandas()\n\ndf_robbery = df_before_2018.loc[df_before_2018['Category']==\"ROBBERY\"]\ndf_robbery = df_robbery[df_robbery[\"Year\"] == 2012]\ndf_robbery_pride = df_robbery[df_robbery['Date'] == '2012-6-24']\n\nSF_map = folium.plugins.DualMap(location=[37.77919, -122.41914],\n                    zoom_start = 12,\n                    tiles = \"openstreetmap\")\n\nconstraint = (df_before_2018['Category'] == 'ROBBERY') & (df_before_2018['Year'] >= 2011) & (df_before_2018['Year'] <= 2012) & (df_before_2018['Resolution'] == \"ARREST, BOOKED\")\ndf_robbery_heat = df_before_2018.loc[constraint].reset_index(drop=True)\n\n\nget_XY = list(zip(list(df_robbery_pride[\"Y\"]), list(df_robbery_pride[\"X\"])))\n\nSF_map = folium.Map([37.77919, -122.41914], zoom_start=13, tiles = \"openstreetmap\")\nfolium.Marker([37.77351584799628, -122.42148577465927], popup=\"Market Street\").add_to(SF_map)\nfolium.Marker([37.78907067508782, -122.3929690574588], popup=\"Beala Street\").add_to(SF_map)\nfolium.Marker([37.77295458293956, -122.40701151351163], popup='8th Street').add_to(SF_map)\n\nfor x,y in get_XY:\n    folium.CircleMarker([x, y],\n                    radius=2,\n                    color='red',\n                    ).add_to(SF_map)\n\n\nx_y_robbery = list(zip(list(df_robbery_heat[\"Y\"]), list(df_robbery_heat[\"X\"])))\n\nHeatMap(x_y_robbery, min_opacity=0.35, overlay=True).add_to(SF_map)\n\nSF_map\n\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\nThe incidence of robbery is relatively high in the near Market Street, indicating that criminals are more prone to commit robbery in crowded areas, thus increasing their chances of escape. Additionally, the buildings and blocks in the Market Street area are more densely packed, offering additional cover and refuge for criminals.\nThis observation also aligns with the result of the heatmap regarding robbery occurrence in 2011 and 2012, as the map above indicates. It reveals the fact that areas with a high concentration of stores and a large population, along with a complex urban infrastructure, are more susceptible to robbery incidents.\nHowever, despite the fact that the Tenderloin district where Market Street located had the highest number of robbery incidents, the data implies that it was not the most active police district. This fact can be counted to the assumption that there was a lack of police power resources in Tenderloin district."
  },
  {
    "objectID": "pages/san_francisco.html#interactive-visualization-police-district-performance",
    "href": "pages/san_francisco.html#interactive-visualization-police-district-performance",
    "title": "Analysis and Visualization",
    "section": "2.3 Interactive Visualization: Police district performance",
    "text": "2.3 Interactive Visualization: Police district performance\n\nHow does the police perform in the different districts?\n\nAs the activities of police can be a key factor that effect on the crime rates, we therefore would like to see how the number of crimes has changed based on different districts. The data are used and maintained by the Police Department, which indicates that the number of records reflects the activities of the police districts. The incidents that are not reported and recorded is excluded to the scope of our discussion.\nWe normalized the occurrences of crime incidents and then created an interactive visualization to enable easy inspection of the normalized number of incidents in each police district.\n\n\nShow the code\noutput_notebook()\ndataset = pl.read_csv('../data/before_2018.csv')\n\ndata = (\n  dataset\n  .groupby(['Hour', 'PdDistrict'])\n  .agg(pl.count().alias('Occurence'))\n  # .with_columns(pl.col('count').alias('Occurence'))\n  .sort('Hour')\n).to_pandas()\n\ndata['Sum'] = data.groupby('PdDistrict')['Occurence'].transform('sum')\ndata['Norm'] = data['Occurence'] / data['Sum']\ndata = data.pivot_table(index='Hour', columns='PdDistrict', values='Norm').reset_index()\n\ndistricts = set(['RICHMOND', 'TARAVAL', 'MISSION', 'INGLESIDE', 'SOUTHERN', 'NORTHERN', 'TENDERLOIN', 'CENTRAL', 'BAYVIEW', 'PARK'])\n\nsource = ColumnDataSource(data)\nhours = data['Hour'].unique()\nhours = sorted(hours)\np = figure(title=\"Police District\", x_axis_label='Hour of the day', y_axis_label='Percentage Frequency', \n           x_range = FactorRange(factors=[str(hour) for hour in hours]))\nbar = {}\nfor indx, i in enumerate(districts):\n    bar[i] = p.vbar(x=\"Hour\", top=i, width=0.3, \n                    source=source, legend_label=i, muted_alpha=0.2, muted=False, color=Category20[14][indx])\np.legend.title = \"Police District\"\np.legend.location = \"top_left\"\np.legend.click_policy = \"mute\"\np.legend.label_text_color = \"black\"\np.legend.title_text_color = \"black\"\nshow(p)\n\n\n\n    \n        \n        Loading BokehJS ...\n    \n\n\n\n\n\n\n\n  \n\n\n\n\n\nThrough the interactive visualization, users are able to select the district they are interested in to observe the data. From the visualization, we can first get the information that each police district has the similar pattern of activities: almost all districts has the relatively high frequency of criminals during 7 am to 23 pm, with the peak at 11 am. It can be reflected that there are more active police resources working during day shift.\nHowever the normalized occurrence of crimes has decreased by half during 0 am to 7 am, and the bottom occurs at the timeslot of 4 am to 5 am. In general, Park District, Taravel District and Southern District were likely to have the best performance due to the relatively larger amount of crime records. Police in Tenderloin District has better performance than Central District at the timeslots of 4-7 am and 12-16 pm, however, however it was less performed than Central District from 17 pm to 3 am.\nHowever, by inspecting in the data of the total occurrence of all categories of crimes, we were not able to catch an apparent correlation between the pattern of crimes and the activity of police districts."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About this site",
    "section": "",
    "text": "Welcome to the site of SocViz, a project created as part of the Social Data & Visualization course taught at the Technical University of Denmark (DTU).\nThe site currently features two investigations: - An investigation into crime activities across various police districts in San Francisco. - An investigation into forecast data for Melbourne, Australia.\nOur aim is to present our findings in a concise and engaging manner through appealing visuals and interactive plots.\nThe site’s design is built on a custom implementation that takes inspiration from Edward Tufte’s principles and incorporates elements from the Neat CSS framework.\nWe are delighted to have you here and hope that you not only enjoy your time on the site but also learn something new as you delve deeper into our content.\n\nStatic site generation and code execution\nThis site is generated using Quarto due to its appealing features for scientific and technical publications.\nQuarto provides an extension to the Markdown formatting language through its .qmd file format, also known as Quarto documents. The Quarto engine can execute code blocks within these documents using the Python interpreter, preferably in a self-contained virtual environment.\nThese documents are processed by Haskell Pandoc to read and export them into various file formats, such as HTML. The resulting HTML is then presented as a static site, which we have published on GitHub Pages.\n\n\n\n\nReuseCC"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Get in touch",
    "section": "",
    "text": "We are open to engagement if you are interested in the endeavor of visual storytelling and value the impact that data can have in understanding our world. You are also welcome to create issues on GitHub if you have suggestions for improving the site or if you find any bugs.\nTo get in touch, you can reach out to us through GitHub either in the Discussions section or by using the contact details found on our public profiles, which you can locate under the Contributors section.\n\n\n\nReuseCC"
  }
]